{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/data/students/bigdata_internet/lab4/log_tcp_complete_classes.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = spark.read.load(input_path,format=\"csv\", header=True, inferSchema=True,sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectionsPerService(classvalue):\n",
    "    instance = 1\n",
    "    return int(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getServicename(classandservie):\n",
    "    classword,service = classandservie.split(':')\n",
    "    return service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = input_df.select(\"class:207\").withColumnRenamed(\"class:207\",\"classvalue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(classvalue)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"isService\", lambda classvalue: getServicename(classvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_df = class_df.selectExpr(\"isService(classvalue) as service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|service|\n",
      "+-------+\n",
      "| google|\n",
      "| google|\n",
      "| google|\n",
      "| google|\n",
      "+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(service)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"isConnection\", lambda service: connectionsPerService(service),\"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classvalue_instance_df = service_df.selectExpr(\"service\",\"isConnection(service) as instance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|service|instance|\n",
      "+-------+--------+\n",
      "| google|       1|\n",
      "| google|       1|\n",
      "| google|       1|\n",
      "| google|       1|\n",
      "+-------+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classvalue_instance_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_connections_per_service_df = classvalue_instance_df.groupBy(\"service\").sum(\"instance\")\\\n",
    " .withColumnRenamed(\"sum(instance)\",\"total instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+\n",
      "|  service|total instances|\n",
      "+---------+---------------+\n",
      "|instagram|          10000|\n",
      "|  spotify|          10000|\n",
      "|     bing|          10000|\n",
      "|   amazon|          10000|\n",
      "+---------+---------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_connections_per_service_df.show(4)\n",
    "total_connections_per_service_df.count() #Â number of different services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since Spark only uses numerical values for classification i need to not consider the \n",
    "# cathergorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 \n",
    "# dataframe with chosen features for classification \n",
    "df_temp = input_df.select(\"class:207\"\\\n",
    "                          ,\"c_pkts_all:3\"\\\n",
    "                          ,\"s_pkts_all:17\"\\\n",
    "                          ,\"c_ack_cnt:5\"\\\n",
    "                          ,\"s_ack_cnt:19\"\\\n",
    "                          ,\"c_bytes_uniq:7\"\\\n",
    "                          ,\"s_bytes_uniq:21\"\\\n",
    "                          ,\"c_pkts_data:8\"\\\n",
    "                          ,\"s_pkts_data:22\"\\\n",
    "                          ,\"durat:31\"\\\n",
    "                          ,\"c_first:32\"\\\n",
    "                          ,\"s_first:33\"\\\n",
    "                          ,\"c_first_ack:36\"\\\n",
    "                          ,\"s_first_ack:37\"\\\n",
    "                          ,\"c_rtt_avg:45\"\\\n",
    "                          ,\"s_rtt_avg:52\"\\\n",
    "                          ,\"c_rtt_std:48\"\\\n",
    "                          ,\"s_rtt_std:55\"\\\n",
    "                          ,\"c_rtt_cnt:49\"\\\n",
    "                          ,\"s_rtt_cnt:56\"\\\n",
    "                          ,\"c_mss:70\"\\\n",
    "                          ,\"s_mss:93\"\\\n",
    "                          ,\"c_mss_max:71\"\\\n",
    "                          ,\"s_mss_max:94\"\\\n",
    "                          ,\"http_req_cnt:111\"\\\n",
    "                          ,\"http_res_cnt:112\"\\\n",
    "                          ,\"c_rtt_min:46\"\\\n",
    "                          ,\"s_rtt_min:53\"\\\n",
    "                          ,\"c_rtt_max:47\"\\\n",
    "                          ,\"s_rtt_max:54\"\\\n",
    "                          ,\"c_mss_min:72\",\\\n",
    "                          \"s_mss_min:95\"\\\n",
    "                          ,\"c_win_max:73\"\\\n",
    "                          ,\"s_win_max:96\"\\\n",
    "                          ,\"c_win_min:74\"\\\n",
    "                          ,\"s_win_min:97\"\\\n",
    "                          ,\"c_cwin_max:76\"\\\n",
    "                          ,\"s_cwin_max:99\"\\\n",
    "                          ,\"c_cwin_min:77\"\\\n",
    "                          ,\"s_cwin_min:100\"\\\n",
    "                          ,\"c_cwin_ini:78\"\\\n",
    "                          ,\"s_cwin_ini:101\"\\\n",
    "                          ,\"c_appdataT:123\"\\\n",
    "                          ,\"s_appdataT:124\"\\\n",
    "                          ,\"c_appdataB:125\"\\\n",
    "                          ,\"s_appdataB:126\"\\\n",
    "                          ,\"c_last:34\"\\\n",
    "                          ,\"s_last:35\"\\\n",
    "                          ,\"c_bytes_retx:11\"\\\n",
    "                          ,\"s_bytes_retx:25\"\n",
    "                          )\\\n",
    ".withColumnRenamed(\"class:207\",\"classvalue\")\\\n",
    ".withColumnRenamed(\"c_pkts_all:3\",\"c_pkts_all\")\\\n",
    ".withColumnRenamed(\"s_pkts_all:17\",\"s_pkts_all\")\\\n",
    ".withColumnRenamed(\"c_ack_cnt:5\",\"c_ack_cnt\")\\\n",
    ".withColumnRenamed(\"s_ack_cnt:19\",\"s_ack_cnt\")\\\n",
    ".withColumnRenamed(\"c_bytes_uniq:7\",\"c_bytes_uniq\")\\\n",
    ".withColumnRenamed(\"s_bytes_uniq:21\",\"s_bytes_uniq\")\\\n",
    ".withColumnRenamed(\"c_pkts_data:8\",\"c_pkts_data\")\\\n",
    ".withColumnRenamed(\"s_pkts_data:22\",\"s_pkts_data\")\\\n",
    ".withColumnRenamed(\"durat:31\",\"durat\")\\\n",
    ".withColumnRenamed(\"c_first:32\",\"c_first\")\\\n",
    ".withColumnRenamed(\"s_first:33\",\"s_first\")\\\n",
    ".withColumnRenamed(\"c_first_ack:36\",\"c_first_ack\")\\\n",
    ".withColumnRenamed(\"s_first_ack:37\",\"s_first_ack\")\\\n",
    ".withColumnRenamed(\"c_rtt_avg:45\",\"c_rtt_avg\")\\\n",
    ".withColumnRenamed(\"s_rtt_avg:52\",\"s_rtt_avg\")\\\n",
    ".withColumnRenamed(\"c_rtt_std:48\",\"c_rtt_std\")\\\n",
    ".withColumnRenamed(\"s_rtt_std:55\",\"s_rtt_std\")\\\n",
    ".withColumnRenamed(\"c_rtt_cnt:49\",\"c_rtt_cnt\")\\\n",
    ".withColumnRenamed(\"s_rtt_cnt:56\",\"s_rtt_cnt\")\\\n",
    ".withColumnRenamed(\"c_mss:70\",\"c_mss\")\\\n",
    ".withColumnRenamed(\"s_mss:93\",\"s_mss\")\\\n",
    ".withColumnRenamed(\"c_mss_max:71\",\"c_mss_max\")\\\n",
    ".withColumnRenamed(\"s_mss_max:94\",\"s_mss_max\")\\\n",
    ".withColumnRenamed(\"http_req_cnt:111\",\"http_req_cnt\")\\\n",
    ".withColumnRenamed(\"http_res_cnt:112\",\"http_res_cnt\")\\\n",
    ".withColumnRenamed(\"c_rtt_min:46\",\"c_rtt_min\")\\\n",
    ".withColumnRenamed(\"s_rtt_min:53\",\"s_rtt_min\")\\\n",
    ".withColumnRenamed(\"c_rtt_max:47\",\"c_rtt_max\")\\\n",
    ".withColumnRenamed(\"s_rtt_max:54\",\"s_rtt_max\")\\\n",
    ".withColumnRenamed(\"c_mss_min:72\",\"c_mss_min\")\\\n",
    ".withColumnRenamed(\"s_mss_min:95\",\"s_mss_min\")\\\n",
    ".withColumnRenamed(\"c_win_max:73\",\"c_win_max\")\\\n",
    ".withColumnRenamed(\"s_win_max:96\",\"s_win_max\")\\\n",
    ".withColumnRenamed(\"c_win_min:74\",\"c_win_min\")\\\n",
    ".withColumnRenamed(\"s_win_min:97\",\"s_win_min\")\\\n",
    ".withColumnRenamed(\"c_cwin_max:76\",\"c_cwin_max\")\\\n",
    ".withColumnRenamed(\"s_cwin_max:99\",\"s_cwin_max\")\\\n",
    ".withColumnRenamed(\"c_cwin_min:77\",\"c_cwin_min\")\\\n",
    ".withColumnRenamed(\"s_cwin_min:100\",\"s_cwin_min\")\\\n",
    ".withColumnRenamed(\"c_cwin_ini:78\",\"c_cwin_ini\")\\\n",
    ".withColumnRenamed(\"s_cwin_ini:101\",\"s_cwin_ini\")\\\n",
    ".withColumnRenamed(\"c_appdataT:123\",\"c_appdataT\")\\\n",
    ".withColumnRenamed(\"s_appdataT:124\",\"s_appdataT\")\\\n",
    ".withColumnRenamed(\"c_appdataB:125\",\"c_appdataB\")\\\n",
    ".withColumnRenamed(\"s_appdataB:126\",\"s_appdataB\")\\\n",
    ".withColumnRenamed(\"c_last:34\",\"c_last\")\\\n",
    ".withColumnRenamed(\"s_last:35\",\"s_last\")\\\n",
    ".withColumnRenamed(\"c_bytes_retx:11\",\"c_bytes_retx\")\\\n",
    ".withColumnRenamed(\"s_bytes_retx:25\",\"s_bytes_retx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_for_classification__simple = df_temp.selectExpr(\"isService(classvalue) as service\"\\\n",
    "                                                          ,\"c_pkts_all\"\\\n",
    "                                                          ,\"s_pkts_all\"\\\n",
    "                                                          ,\"c_ack_cnt\"\\\n",
    "                                                          ,\"s_ack_cnt\"\\\n",
    "                                                          ,\"c_bytes_uniq\"\\\n",
    "                                                          ,\"s_bytes_uniq\"\\\n",
    "                                                          ,\"c_pkts_data\"\\\n",
    "                                                          ,\"s_pkts_data\"\\\n",
    "                                                          ,\"durat\"\\\n",
    "                                                          ,\"c_first\"\\\n",
    "                                                          ,\"s_first\"\\\n",
    "                                                          ,\"c_first_ack\"\\\n",
    "                                                          ,\"s_first_ack\"\\\n",
    "                                                          ,\"c_rtt_avg\"\\\n",
    "                                                          ,\"s_rtt_avg\"\\\n",
    "                                                          ,\"c_rtt_std\"\\\n",
    "                                                          ,\"s_rtt_std\"\\\n",
    "                                                          ,\"c_rtt_cnt\"\\\n",
    "                                                          ,\"s_rtt_cnt\"\\\n",
    "                                                          ,\"c_mss\"\\\n",
    "                                                          ,\"s_mss\"\\\n",
    "                                                          ,\"c_mss_max\"\\\n",
    "                                                          ,\"s_mss_max\"\\\n",
    "                                                          ,\"http_req_cnt\"\\\n",
    "                                                          ,\"http_res_cnt\"\\\n",
    "                                                          ,\"c_rtt_min\"\\\n",
    "                                                          ,\"s_rtt_min\"\\\n",
    "                                                          ,\"c_rtt_max\"\\\n",
    "                                                          ,\"s_rtt_max\"\\\n",
    "                                                          ,\"c_mss_min\"\\\n",
    "                                                          ,\"s_mss_min\"\\\n",
    "                                                          ,\"c_win_max\"\\\n",
    "                                                          ,\"s_win_max\"\\\n",
    "                                                          ,\"c_win_min\"\\\n",
    "                                                          ,\"s_win_min\"\\\n",
    "                                                          ,\"c_cwin_max\"\\\n",
    "                                                          ,\"s_cwin_max\"\\\n",
    "                                                          ,\"c_cwin_min\"\\\n",
    "                                                          ,\"s_cwin_min\"\\\n",
    "                                                          ,\"c_cwin_ini\"\\\n",
    "                                                          ,\"s_cwin_ini\"\\\n",
    "                                                          ,\"c_appdataT\"\\\n",
    "                                                          ,\"s_appdataT\"\\\n",
    "                                                          ,\"c_appdataB\"\\\n",
    "                                                          ,\"s_appdataB\"\\\n",
    "                                                          ,\"c_last\"\\\n",
    "                                                          ,\"s_last\"\\\n",
    "                                                          ,\"c_bytes_retx\"\\\n",
    "                                                          ,\"s_bytes_retx\"\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 Read and split the data after feature selection \n",
    "training_df,test_df = dataframe_for_classification__simple.randomSplit([0.75,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol = \"service\", outputCol = \"service index\", handleInvalid = \"keep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VectorAssembler(inputCols = [\"c_pkts_all\",\"s_pkts_all\"\\\n",
    "                                  ,\"c_ack_cnt\",\"s_ack_cnt\"\\\n",
    "                                  ,\"c_bytes_uniq\",\"s_bytes_uniq\"\\\n",
    "                                  ,\"c_pkts_data\",\"s_pkts_data\"\\\n",
    "                                  ,\"durat\",\"c_first\",\"s_first\",\"c_first_ack\"\\\n",
    "                                  ,\"s_first_ack\",\"c_rtt_avg\"\\\n",
    "                                  ,\"s_rtt_avg\",\"c_rtt_std\"\\\n",
    "                                  ,\"s_rtt_std\",\"c_rtt_cnt\"\\\n",
    "                                  ,\"s_rtt_cnt\",\"c_mss\"\\\n",
    "                                  ,\"s_mss\",\"c_mss_max\"\\\n",
    "                                  ,\"s_mss_max\",\"http_req_cnt\"\\\n",
    "                                  ,\"http_res_cnt\",\"c_rtt_min\"\\\n",
    "                                  ,\"s_rtt_min\",\"c_rtt_max\"\\\n",
    "                                  ,\"s_rtt_max\",\"c_mss_min\"\\\n",
    "                                  ,\"s_mss_min\",\"c_win_max\"\\\n",
    "                                  ,\"s_win_max\",\"c_win_min\"\\\n",
    "                                  ,\"s_win_min\",\"c_cwin_max\"\\\n",
    "                                  ,\"s_cwin_max\",\"c_cwin_min\"\\\n",
    "                                  ,\"s_cwin_min\",\"c_cwin_ini\"\\\n",
    "                                  ,\"s_cwin_ini\",\"c_appdataT\"\\\n",
    "                                  ,\"s_appdataT\",\"c_appdataB\"\\\n",
    "                                  ,\"s_appdataB\",\"c_last\"\\\n",
    "                                  ,\"s_last\",\"c_bytes_retx\"\\\n",
    "                                  ,\"s_bytes_retx\"]\\\n",
    "                     , outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "scaler = StandardScaler(inputCol = \"features\", outputCol = \"scaledFeatures\", withStd = True, withMean = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresColumnToUse = \"scaledFeatures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3 Training two different models\n",
    "# train a decision tree\n",
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(labelCol = \"service index\" , featuresCol = featuresColumnToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the pipeline for the decision tree\n",
    "from pyspark.ml import Pipeline\n",
    "pipelineTree = Pipeline(stages=[indexer,va, scaler,decision_tree])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a random forest classifier\n",
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(labelCol = \"service index\", featuresCol = featuresColumnToUse, numTrees = 20,maxDepth = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Pipeline for the random forest \n",
    "pipelineRandomForest = Pipeline(stages=[indexer,va,scaler,random_forest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.4 Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the decision tree\n",
    "dt_accuracy_training_eval = MulticlassClassificationEvaluator(labelCol = \"service index\", predictionCol = \"prediction\", metricName = \"accuracy\")\n",
    "dt_f1_training_eval = MulticlassClassificationEvaluator(labelCol = \"service index\", predictionCol = \"prediction\", metricName = \"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the random forest\n",
    "rf_accuracy_training_eval = MulticlassClassificationEvaluator(labelCol = \"service index\", predictionCol = \"prediction\", metricName = \"accuracy\")\n",
    "rf_f1_training_eval = MulticlassClassificationEvaluator(labelCol = \"service index\", predictionCol = \"prediction\", metricName = \"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Tuning the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGridTree = ParamGridBuilder()\\\n",
    ".addGrid(decision_tree.maxDepth, [2,10,12])\\\n",
    ".addGrid(decision_tree.impurity, [\"Gini\",\"Entropy\"])\\\n",
    ".build()\n",
    "\n",
    "\n",
    "paramGridRandomForest = ParamGridBuilder()\\\n",
    ".addGrid(random_forest.maxDepth, [2,10,12])\\\n",
    ".addGrid(random_forest.impurity, [\"Gini\",\"Entropy\"])\\\n",
    ".addGrid(random_forest.numTrees, [15,20,25])\\\n",
    ".build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dt = CrossValidator(estimator=pipelineTree\\\n",
    "                       ,evaluator=dt_accuracy_training_eval\\\n",
    "                       ,estimatorParamMaps = paramGridTree\\\n",
    "                       ,numFolds=3)\n",
    "\n",
    "cv_rf = CrossValidator(estimator=pipelineRandomForest\\\n",
    "                       ,evaluator=rf_accuracy_training_eval\\\n",
    "                       ,estimatorParamMaps = paramGridRandomForest\\\n",
    "                       , numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModelDecisionTree = cv_dt.fit(training_df) \n",
    "cvModelRandomForest = cv_rf.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDFDecisionTree=cvModelDecisionTree.transform(training_df)\n",
    "finalDFRandomForest=cvModelRandomForest.transform(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "#cvModelDecisionTree.getEstimatorParamMaps() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index of the model\n",
    "numpy.argmax(cvModelDecisionTree.avgMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3721507187157899,\n",
       " 0.372957482420219,\n",
       " 0.9658794503262684,\n",
       " 0.9731691473536938,\n",
       " 0.9733604175564261,\n",
       " 0.9778102512864497]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy results for all parameters tried\n",
    "cvModelDecisionTree.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree on test set:  0.9796040313906704\n",
      "F1 of Decision Tree on test set:  0.979592836831596\n"
     ]
    }
   ],
   "source": [
    "final_dt_testDf = cvModelDecisionTree.transform(test_df)\n",
    "dt_accuracy_test_eval = MulticlassClassificationEvaluator(labelCol = \"service index\", predictionCol = \"prediction\", metricName = \"accuracy\")\n",
    "print(\"Accuracy of Decision Tree on test set: \",dt_accuracy_test_eval.evaluate(final_dt_testDf))\n",
    "dt_f1_test_eval = MulticlassClassificationEvaluator(labelCol = \"service index\", predictionCol = \"prediction\", metricName = \"f1\")\n",
    "print(\"F1 of Decision Tree on test set: \",dt_f1_test_eval.evaluate(final_dt_testDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7086375226799105,\n",
       " 0.7363698741019857,\n",
       " 0.7243171030173302,\n",
       " 0.6894272249373093,\n",
       " 0.7187216840211644,\n",
       " 0.7210604181769504,\n",
       " 0.9701087407272235,\n",
       " 0.9694822628399986,\n",
       " 0.9704025690269837,\n",
       " 0.9699258132118802,\n",
       " 0.9700215947739583,\n",
       " 0.969760827531071,\n",
       " 0.9794842057346562,\n",
       " 0.9791937325493275,\n",
       " 0.9792203795436007,\n",
       " 0.9790713526100359,\n",
       " 0.9798435980856836,\n",
       " 0.9793794343888664]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModelRandomForest.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest on test set:  0.9815559893239851\n",
      "F1 of Random Forest on test set:  0.9815464651455406\n"
     ]
    }
   ],
   "source": [
    "final_rf_testDf = cvModelRandomForest.transform(test_df)\n",
    "rf_accuracy_test_eval = MulticlassClassificationEvaluator(labelCol = \"service index\", predictionCol = \"prediction\", metricName = \"accuracy\")\n",
    "print(\"Accuracy of Random Forest on test set: \",rf_accuracy_test_eval.evaluate(final_rf_testDf))\n",
    "rf_f1_test_eval = MulticlassClassificationEvaluator(labelCol = \"service index\", predictionCol = \"prediction\", metricName = \"f1\")\n",
    "print(\"F1 of Random Forest on test set: \",rf_f1_test_eval.evaluate(final_rf_testDf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
