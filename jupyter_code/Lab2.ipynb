{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"/data/students/bigdata_internet/lab2/word_frequency.tsv\")\n",
    "outputPath = \"lab2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can you take a look at some of the lines of the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some of the line of the input rdd:  ['have\\t338996', 'bought\\t46988', 'several\\t19688', 'of\\t792000', 'Vitality\\t252']\n"
     ]
    }
   ],
   "source": [
    "somelines = rdd.take(5)\n",
    "print('some of the line of the input rdd: ',somelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many words does it contain? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of lines (aka words) in the input rdd 339819\n"
     ]
    }
   ],
   "source": [
    "numlines = rdd.count()\n",
    "print('Total number of lines (aka words) in the input rdd', numlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the lines containing words that start with a prefix (a string) that is a parameter of the script,\n",
    "# i.e., a global variable PREFIX .\n",
    "PREFIX = 'ho'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find the prefix and keep the line associated \n",
    "def findprefix(line, Prefix):\n",
    "    PREFIX = Prefix\n",
    "    # quality is good    87367\n",
    "    # the 'quality' prefix should be the first 0:len(PREFIX) values \n",
    "    # i also don't care what comes after the orefix, it just has to be there\n",
    "    if line[0:len(PREFIX)] == PREFIX:\n",
    "        return True\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the rdd that contains the lines filtered by the desired prefix\n",
    "filtered_by_prefix_rdd = rdd.filter(lambda line: findprefix(line,PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some lines of the filtered prefix rdd:  ['hot\\t32944', 'home\\t17995', 'however\\t12492', 'holds\\t1762', 'hot\"\\t108']\n"
     ]
    }
   ],
   "source": [
    "print('Some lines of the filtered prefix rdd: ',filtered_by_prefix_rdd.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in the filtered prefix rdd:  1519\n"
     ]
    }
   ],
   "source": [
    "print('Number of lines in the filtered prefix rdd: ',filtered_by_prefix_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result is the set of lines ( word\\tfreq ) that satisfy the filtering operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print on the standard output:\n",
    "    # The number of selected lines\n",
    "    # The maximum frequency ( maxfreq ) among the ones of the selected lines (i.e., the maximum value of\n",
    "    # freq in the lines obtained by applying the filter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split the text from the frequency values for each line\n",
    "def splitline(line):\n",
    "    description, freq = line.split(\"\\t\")\n",
    "    return int(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd containing only the frequency values \n",
    "frequencies_rdd = filtered_by_prefix_rdd.map(splitline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32944, 17995, 12492, 1762, 108, 1, 8668, 4730, 152, 6]\n"
     ]
    }
   ],
   "source": [
    "print(frequencies_rdd.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find the maximum value for all the frequencies\n",
    "def findMax(f1,f2):\n",
    "    if f1>f2:\n",
    "        return f1\n",
    "    elif f2>f1:\n",
    "        return f2\n",
    "    else:\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the maximm value of frequency \n",
    "maxfreq_o = frequencies_rdd.reduce(findMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max frequency value is:  36264\n"
     ]
    }
   ],
   "source": [
    "print('The max frequency value is: ',maxfreq_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Filter most frequent words\n",
    "# Keep only the lines with a frequency freq greater than 0.8*maxfreq ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to select the line that satisfy the condition on frequency\n",
    "def keepsome(line, Maxfreq):\n",
    "    maxfreq = Maxfreq\n",
    "    description, freq = line.split(\"\\t\")\n",
    "    freq = int(freq)\n",
    "    if freq >= 0.8*maxfreq:\n",
    "        return True\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the rdd that contains only values which frequency satisfies the threshold value\n",
    "greater_than_rdd = filtered_by_prefix_rdd.filter(lambda line: keepsome(line,maxfreq_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some values in the filtered by threshold frequency rdd:  ['hot\\t32944', 'how\\t36264']\n"
     ]
    }
   ],
   "source": [
    "print('Some values in the filtered by threshold frequency rdd: ',greater_than_rdd.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3\n",
    "# Count the number of selected lines and print this number on the standard output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in the threshold rdd:  2\n"
     ]
    }
   ],
   "source": [
    "print('Number of lines in the threshold rdd: ',greater_than_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the selected words (without frequency) in an output folder for inspecting the results\n",
    "# the operation is \n",
    "#greater_than_rdd.saveAsTextFile(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1\n",
    "# Run you application locally on Jupyter web interface by using the PySpark (Local) kernel \n",
    "# and select only the lines containing the words starting with “ho” from the the HDFS file\n",
    "# /data/students/bigdata_internet/lab2/word_frequency.tsv .\n",
    "# going to top and changing the prefix and kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Python script to be executed with the spark-submit command. Note: the prefix and\n",
    "# the output_folder must be specified by two command line arguments (Hint: use sys.argv[] ) . \n",
    "# Run your script and select only the lines containing the words starting with \"ho\" \n",
    "# from the content of the HDFS file /data/students/bigdata_internet/lab2/word_frequency.tsv .\n",
    "\n",
    "# s274990@jupyter-s274990:~/newLabs/lab2$ spark-submit --master local --deploy-mode client lab2_2.py ho lab2/\n",
    "# WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1425774/lib/spark) overrides detected (/opt/cloudera/parcels/CDH/lib/spark).\n",
    "# WARNING: Running spark-class from user-defined location.\n",
    "# 20/08/07 10:19:10 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
    "# 20/08/07 10:19:10 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
    "# 20/08/07 10:19:10 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
    "# 20/08/07 10:19:10 WARN util.Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
    "# 20/08/07 10:19:10 WARN util.Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
    "# 20/08/07 10:19:10 WARN util.Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
    "# 20/08/07 10:19:10 WARN util.Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
    "# opath:  lab2/\n",
    "# prefix is:  ho\n",
    "# some lines of original rdd:  ['have\\t338996', 'bought\\t46988', 'several\\t19688', 'of\\t792000', 'Vitality\\t252']                                                                                           \n",
    "# total number of lines in rdd:  339819\n",
    "# some lines of the filtered rdd:  ['hot\\t32944', 'home\\t17995', 'however\\t12492', 'holds\\t1762', 'hot\"\\t108']\n",
    "# number of lines in filtered rdd:  1519\n",
    "# filtered_by_prefix_rdd:  ['hot\\t32944', 'home\\t17995', 'however\\t12492', 'holds\\t1762', 'hot\"\\t108']\n",
    "# frequencies_rdd:  1519\n",
    "# max freq:  36264\n",
    "# number of elements found greater than 0.8*maxfreq:  2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the cluster by using the --master yarn option of spark submit\n",
    "\n",
    "\n",
    "# s274990@jupyter-s274990:~/newLabs/lab2$ spark-submit --master yarn --deploy-mode client lab2_2.py ho lab2/\n",
    "# WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1425774/lib/spark) overrides detected (/opt/cloudera/parcels/CDH/lib/spark).\n",
    "# WARNING: Running spark-class from user-defined location.\n",
    "# 20/08/07 10:21:06 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
    "# 20/08/07 10:21:06 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
    "# 20/08/07 10:21:06 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
    "# 20/08/07 10:21:06 WARN util.Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
    "# 20/08/07 10:21:06 WARN util.Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
    "# 20/08/07 10:21:06 WARN util.Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
    "# 20/08/07 10:21:06 WARN util.Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
    "# opath:  lab2/\n",
    "# prefix is:  ho\n",
    "# some lines of original rdd:  ['have\\t338996', 'bought\\t46988', 'several\\t19688', 'of\\t792000', 'Vitality\\t252']                                                                                           \n",
    "# total number of lines in rdd:  339819                                                                                                                                                                     \n",
    "# some lines of the filtered rdd:  ['hot\\t32944', 'home\\t17995', 'however\\t12492', 'holds\\t1762', 'hot\"\\t108']\n",
    "# number of lines in filtered rdd:  1519\n",
    "# filtered_by_prefix_rdd:  ['hot\\t32944', 'home\\t17995', 'however\\t12492', 'holds\\t1762', 'hot\"\\t108']\n",
    "# frequencies_rdd:  1519\n",
    "# max freq:  36264\n",
    "# number of elements found greater than 0.8*maxfreq:  2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question: Take note of the time that it takes to run the applications in the two different submission modes. Is\n",
    "#there a difference in time? Can you give a plausible explanation?\n",
    "# yarn ~ 22 seconds\n",
    "# local ~ 10 seconds\n",
    "# The difference in time can probably be attributed to how the data is stored and operated on.\n",
    "# using yarn means using the cluster and such means that the code is run in parallel on the different bloks in different nodes \n",
    "# using the local means the data is all stored in one place so the code is run only on that part which consumes less time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
